{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open(\"nietzsche.txt\", \"r\") \n",
    "data = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int_data = []\n",
    "dictionary = {}\n",
    "reverse_dictionary = {}\n",
    "dic_len = 0\n",
    "for i in range(len(data)):\n",
    "    if data[i] in dictionary:\n",
    "        int_data.append(dictionary[data[i]])\n",
    "    else:\n",
    "        dictionary[data[i]] = dic_len\n",
    "        reverse_dictionary[dic_len] = data[i]\n",
    "        dic_len += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def to_one_hat(data, dic_len):\n",
    "    out = np.zeros((len(data), dic_len))\n",
    "    for i, d in enumerate(data):\n",
    "        out[i, d] = 1\n",
    "    return out\n",
    "\n",
    "clean_data = to_one_hat(int_data, dic_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len_seq = 40\n",
    "self_overlap = 3\n",
    "\n",
    "last_data = np.zeros((len(data) // (len_seq - self_overlap), len_seq, dic_len))\n",
    "for i in range(0, len(clean_data) - len_seq, len_seq - self_overlap):\n",
    "    last_data[i // (len_seq - self_overlap),:, :] = clean_data[i: i + len_seq , :]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'P', 1: 'R', 2: 'E', 3: 'F', 4: 'A', 5: 'C', 6: '\\n', 7: 'S', 8: 'U', 9: 'O', 10: 'I', 11: 'N', 12: 'G', 13: ' ', 14: 't', 15: 'h', 16: 'a', 17: 'T', 18: 'r', 19: 'u', 20: 'i', 21: 's', 22: 'w', 23: 'o', 24: 'm', 25: 'n', 26: '-', 27: 'e', 28: '?', 29: 'g', 30: 'd', 31: 'f', 32: 'p', 33: 'c', 34: 'l', 35: ',', 36: 'y', 37: 'v', 38: 'b', 39: 'k', 40: ';', 41: '!', 42: '.', 43: 'B', 44: 'z', 45: 'W', 46: 'H', 47: ':', 48: '(', 49: 'j', 50: ')', 51: '\"', 52: 'V', 53: 'L', 54: \"'\", 55: 'D', 56: 'Y', 57: 'K', 58: 'q', 59: 'M', 60: 'x', 61: 'J', 62: '1', 63: '8', 64: '5', 65: '2', 66: '3', 67: '_', 68: '4', 69: '6', 70: '7', 71: '9', 72: '0', 73: 'Q', 74: 'X', 75: '[', 76: ']', 77: 'Z', 78: 'ä', 79: '=', 80: 'æ', 81: 'ë', 82: 'é', 83: 'Æ'}\n"
     ]
    }
   ],
   "source": [
    "print(reverse_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_hidden = 128\n",
    "gru = tf.contrib.rnn.GRUCell(n_hidden)\n",
    "feature_size = dic_len\n",
    "learning_rate = 0.01\n",
    "batch_size = 50\n",
    "\n",
    "input_data = tf.placeholder(dtype=tf.float32, shape=[None, None, feature_size])\n",
    "target_data = tf.placeholder(dtype=tf.float32, shape=[None, None, feature_size])\n",
    "\n",
    "\n",
    "initial_state = gru.zero_state(1, dtype=tf.float32)\n",
    "\n",
    "output, state = tf.nn.dynamic_rnn(gru, input_data, dtype = tf.float32)\n",
    "\n",
    "w = tf.Variable(tf.random_normal([n_hidden, feature_size]))\n",
    "b = tf.Variable(tf.random_normal([feature_size]))\n",
    "                \n",
    "output_reshaped = tf.reshape(output, [-1 , n_hidden])\n",
    "\n",
    "logits = tf.matmul(output_reshaped, w) + b\n",
    "\n",
    "last_output = tf.nn.softmax(tf.reshape(logits, tf.shape(input_data)))\n",
    "\n",
    "preds = tf.argmax(last_output, 2)\n",
    "\n",
    "loss = tf.reduce_mean((target_data - last_output) * (target_data - last_output))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss = 3.679473824799061\n",
      "epoch 1, train loss = 3.0949996849521995\n",
      "epoch 2, train loss = 2.90929121337831\n",
      "epoch 3, train loss = 2.784828462637961\n",
      "epoch 4, train loss = 2.682895469944924\n",
      "epoch 5, train loss = 2.606905061751604\n",
      "epoch 6, train loss = 2.5494548538699746\n",
      "epoch 7, train loss = 2.5061772358603776\n",
      "epoch 8, train loss = 2.469462802633643\n",
      "epoch 9, train loss = 2.439052229747176\n",
      "epoch 10, train loss = 2.41227811248973\n",
      "epoch 11, train loss = 2.3882595845498145\n",
      "epoch 12, train loss = 2.3666033474728465\n",
      "epoch 13, train loss = 2.3481959919445217\n",
      "epoch 14, train loss = 2.3305799239315093\n",
      "epoch 15, train loss = 2.314336543902755\n",
      "epoch 16, train loss = 2.300010702572763\n",
      "epoch 17, train loss = 2.287126758135855\n",
      "epoch 18, train loss = 2.2753186910413206\n",
      "epoch 19, train loss = 2.2643421958200634\n",
      "epoch 20, train loss = 2.25411623576656\n",
      "epoch 21, train loss = 2.245194101240486\n",
      "epoch 22, train loss = 2.236884409096092\n",
      "epoch 23, train loss = 2.2287738197483122\n",
      "epoch 24, train loss = 2.218496820423752\n",
      "epoch 25, train loss = 2.2105182399973273\n",
      "epoch 26, train loss = 2.203712855000049\n",
      "epoch 27, train loss = 2.1972798299975693\n",
      "epoch 28, train loss = 2.1915723085403442\n",
      "epoch 29, train loss = 2.1862551709637046\n"
     ]
    }
   ],
   "source": [
    "#just some config for not getting whole server\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config = tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "epochs_num = 30\n",
    "sess = tf.Session(config = config) \n",
    "sess.run(init)\n",
    "for e in range(epochs_num):\n",
    "    total_loss = 0\n",
    "    n_epochs = len(last_data)//batch_size\n",
    "    for i in range(n_epochs):\n",
    "        batch = last_data[batch_size * i: batch_size * (i+1), :, :]\n",
    "        X_batch, Y_batch = batch[:, 0:len_seq -1, :], batch[:, 1:len_seq, :]\n",
    "        train_loss,_,train_preds = sess.run([loss, optimizer, preds]\n",
    "                                            ,feed_dict = {input_data : X_batch, target_data : Y_batch})\n",
    "        total_loss += train_loss\n",
    "    print(\"epoch {}, train loss = {}\".format(e, total_loss))\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-28-12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Models/model-2017-11-28-12/model'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "dt = datetime.datetime.now().strftime(\"%Y-%m-%d-%H\")\n",
    "print(dt)\n",
    "saver.save(sess, 'Models/model-{}/model'.format(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is a regular cult of\n",
      "suffering. The UNMON of spotker tomances sai's saintiathols ineared in the owmost tamoncessa. 4undred to SOMPer, his heart of Yemanciationtely de=Ægow bi: dever besinessible, Aætiondomening aéceriom all conceéed the maintenction and\n",
      "\"False and withever happin thinder these is helHest at2o\n",
      "traced, in sacallfy fa_ being of a1ST\n",
      "A) onves the mot'. ëontinequal powentryElTron of sfactianity of power, the smilarian\n",
      "self2"
     ]
    }
   ],
   "source": [
    "def to_one_hat(x, dic_len):\n",
    "    out = np.zeros(dic_len)\n",
    "    out[x] = 1\n",
    "    return out\n",
    "\n",
    "test_data = last_data[10000:10001]\n",
    "\n",
    "for i in range(len_seq):\n",
    "    print(reverse_dictionary[np.argmax(test_data[0,i])], end = \"\")\n",
    "for i in range( 400):\n",
    "    test_output, test_preds = sess.run([ last_output, preds] ,feed_dict = {input_data : test_data})\n",
    "    \n",
    "    picked_word = np.random.choice(dic_len, 1, p=test_output[0, -1, :])[0]\n",
    "    print(reverse_dictionary[picked_word],end = \"\")\n",
    "\n",
    "    test_data[0, 0:len_seq - 1, :] = test_data[0, 1:len_seq, :]\n",
    "    test_data[0, len_seq - 1, :] = to_one_hat(picked_word, dic_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
